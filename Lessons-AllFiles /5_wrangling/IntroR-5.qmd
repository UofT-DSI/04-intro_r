---
title: "4.5 Introduction to R: Wrangling"
institute: "Data Science Institute, University of Toronto"
author: "Julia Gallucci"
date: "June, 5, 2023"
format: beamer
editor: visual
---

```{r}
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  # Apply the default chunk hook
  x <- def.chunk.hook(x, options)
  
  # Define the maximum line length
  max_length <- 40
  
  # Split the lines of code
  lines <- strsplit(x, "\n")[[1]]
  
  # Wrap long lines
  wrapped_lines <- lapply(lines, function(line) {
    if (nchar(line) > max_length) {
      # Wrap the line if it exceeds the maximum length
      wrapped_line <- paste(strwrap(line, width = max_length), collapse = "\n")
    } else {
      line
    }
  })
  
  # Join the modified lines back together
  modified_code <- paste(wrapped_lines, collapse = "\n")
  
  # Modify the font size
  modified_code <- paste0("\n \\", "small", "\n\n", modified_code, "\n\n \\normalsize")
  
  # Return the modified code
  modified_code
})

```


```{r, include=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)
library(kableExtra)
library(rgdal)
library(data.table)
```

## Acknowledgements

Slides are adapted from Anjali Silva, originally from Amy Farrow under the supervision of Rohan Alexander, University of Toronto. Slides have been modified by Julia Gallucci, 2023.

## Overview

-   Importing data (Wickham and Grolemund, 2017, Chapter 11; Timbers et al. 2021, Chapter 2) & Saving data
-   Pivot (Wickham and Grolemund, 2017, Chapter 12; Timbers et al. 2021, Chapter 3.4)
-   Joining data (Wickham and Grolemund, 2017, Chapter 13)
-   data.table (Wiley and Wiley, 2020, Chapter 7; https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html)

# Data Import

## Packages and functions for reading in different file types

CSV files

```{r, echo = TRUE, eval=FALSE}
readr::read_csv()
```

Excel workbooks

```{r, echo = TRUE, eval=FALSE}
readxl::read_excel()
```

## Packages and functions for reading in different file types

SPSS files

```{r, echo = TRUE, eval=FALSE}
haven::read_sav()
```

Stata files

```{r, echo = TRUE, eval=FALSE}
haven::read_dta()
```

SAS files

```{r, echo = TRUE, eval=FALSE}
haven::read_sas()
```

## Specifications for import

When the separator isn't a comma:

```{r, echo = TRUE, eval=F}
read_csv("mydata.csv", sep = ";")
```

When the first two lines are metadata:

```{r, echo = TRUE, eval=F}
read_csv("mydata.csv", skip = 2)
```

When there are no column names:

```{r, echo = TRUE, eval=F}
read_csv("mydata.csv", col_names = FALSE)
```

## Import issues

The reader function guesses what data type each column is. This might not always work the way you want. You can specify column types if necessary:

```{r, echo = TRUE, eval=F}
read_csv("mydata.csv",
         col_types = cols(.default = col_character()))
```

## Writing data

To save your dataset created in R as a CSV file

```{r, echo = TRUE, eval=F}
write_csv(mydata, "mydata.csv")
```

# Questions?

# Pivot

## Tidy data

Rules for tidy data:

1.  Each variable must have its own column.
2.  Each observation must have its own row.
3.  Each value must have its own cell.

Pivoting will help you get to tidy data form.

## Pivot

-   refers to the process of transforming data from a "long" format to a "wide" format or vice versa

## Tidy data

Let's say we have a dataset with the weights of two pet cats:

```{r, echo = TRUE}
wide_data <- tibble(
  year = c(2017, 2018, 2019, 2020, 2021, 2022),
  milo = c(4, 6.3, 8, 7.9, 8.1, 8.1),
  kitty = c(15.6, 15.9, 14, 12.2, 10.9, 9.9)
)
wide_data
```

## Tidy data

**`pivot_longer()`**: used to transform data from a wide format to a long format. It "lengthens" data, increasing the number of rows and decreasing the number of columns

```{r, echo = TRUE}
long_data <- wide_data %>%
  pivot_longer(cols = c("milo", "kitty"),
               names_to = "cat",
               values_to = "weight")
long_data
```

## Tidy data

**`pivot_wider()`**: used to transform data from a long format to a wide format. It "widens" data, increasing the number of columns and decreasing the number of rows

```{r, echo = TRUE}
long_data %>%
  pivot_wider(names_from = "cat",
              values_from = "weight")
```

This may be useful when making a summary table to display.

# Questions?

# Join

## Mutating joins

Joins combine tables based on an identified key, usually a variable that the two tables share in common.

```{r, echo = TRUE, eval=FALSE}
left_join(), right_join(), full_join(), inner_join()
```

```{r echo=FALSE}
knitr::include_graphics("join-venn.png")
```

## Keys

1.  Primary keys uniquely identify an observation in its table
2.  Foreign keys uniquely identify an observation in another table

Primary keys may match foreign keys, if the variable is present in both tables and has the same name.

Primary and foreign keys have a specific relation: it could be one-to-one, or one-to-many.

## Example using toy data

We will make two small datasets, each with year as a variable. Year will be the key we use to join.

```{r, echo = TRUE}
employment <- tibble(year = c(1990, 1991, 1992, 1994),
                     rate = c(.05, .02, .04, .02))
employment
```

## Example using toy data

```{r, echo = TRUE}
housing <- tibble(date = c(1991, 1992, 1993, 1994, 1995),
                  rate = c(0.89, 0.6, 0.75, 0.88, 0.9))
housing
```

## Inner Join

The rows correspond to years that are present in both `employment` and `housing`:

```{r, echo = TRUE}
employment %>%
  inner_join(housing, by = c("year" = "date"))
```

Because both tables have a variable named `rate`, the joined table has columns named `rate.x` from the left table (employment) and `rate.y` from the right table (housing).

## Left Join

The rows correspond to years that are present in both `employment`but not necessarily `housing`:

```{r, echo = TRUE}
employment %>%
  left_join(housing, by = c("year" = "date"))
```

Missing values are filled with `NA`.

## Right Join

The rows correspond to years that are present in `housing` but not necessarily `employment`:

```{r, echo = TRUE}
employment %>%
  right_join(housing, by = c("year" = "date"))
```

## Full Join

The rows correspond to years that are present in `employment`or `housing`:

```{r, echo = TRUE}
employment %>%
  full_join(housing, by = c("year" = "date"))
```

## Filtering joins

Semi joins keep all observations in the employment table that have a match in the housing table:

```{r, echo = TRUE}
employment %>%
  semi_join(housing, by = c("year" = "date"))
```

## Filtering joins

Anti joins drop all observations in employment that have a match in housing:

```{r, echo = TRUE}
employment %>%
  anti_join(housing, by = c("year" = "date"))
```

# Questions?

# data.table

## Introduction

data.tables are faster and more memory efficient than data.frames, making them better suited for large operations on large data sets.

They are keyed, which makes it possible to use binary search. A key is an index, created from column(s) in the data.table. It may or may not be unique.

## data.table

```{r, echo = TRUE}
data(iris)

dt_iris <- as.data.table(iris)

dt_iris
```

## data.table

You can see how many tables are stored and what size they are:

```{r, echo = TRUE}
tables()
```

## data.table

To get information about our data, we can use sapply and class:

```{r, echo = TRUE}
sapply(dt_iris, class)
```

## data.table

To check if the data.table has a key:

```{r, echo = TRUE}
haskey(dt_iris)
```

To set a key:

```{r, echo = TRUE}
setkey(dt_iris, Species)
haskey(dt_iris)
```

## General form

datatable\[i, j, k\]

Where:

-   from datatable
-   i is selected and/or filtered
-   j is calculated
-   k is grouped by

## Subsetting rows

```{r , echo = TRUE, eval=FALSE}
dt_iris[Petal.Width > 0.5]
```

## Selecting columns

Selecting a column to return as a vector:

```{r, echo = TRUE, eval=FALSE}
dt_iris[, Species]
```

## Selecting columns

Selecting a column to return as a data.table:

```{r, echo = TRUE, eval=FALSE}
dt_iris[, list(Species)]
```

## Computations

Counting the number of cases where Petal.Length plus Petal.Width is greater than 2:

```{r, echo = TRUE, eval=FALSE}
dt_iris[, sum((Petal.Length + Petal.Width) > 2)]
```

## Combining subsetting and computation

Counting the number of cases where Species is "setosa" and Petal.Length plus Petal.Width is greater than 2:

```{r, echo = TRUE, eval=FALSE}
dt_iris[Species == "setosa", sum((Petal.Length + Petal.Width) > 2)]
```

## Counting observations in current group

```{r, echo = TRUE, eval=FALSE}
dt_iris[Species == "setosa", .N]
```

## Aggregations

Counting the number in each Species group:

```{r, echo = TRUE, eval=FALSE}
dt_iris[, .(.N), by = .(Species)]
```

## Sorting

```{r, echo = TRUE, eval=FALSE}
dt_iris[Petal.Width > 1, .(mean(Petal.Length)), keyby = .(Species)]
```

## Ordering

Ordering by Species and then by reverse Petal.Width:

```{r, echo = TRUE, eval=FALSE}
dt_iris[order(Species, -Petal.Width)]
```

## Grouping by expression rather than column

Grouping those that have Petal.Length greater/not than 4, and Petal.Width greater/not than 1:

```{r, echo = TRUE, eval=FALSE}
dt_iris[, .N, .(Petal.Length > 4, Petal.Width > 1)]
```

## Computations for multiple columns

Taking the mean of all columns (except the grouping column, Species) using lapply and .SD:

```{r, echo = TRUE, eval=FALSE}
dt_iris[, lapply(.SD, mean), by = Species]
```

## Subsetting for each group

Getting the first two rows for all columns, for each Species:

```{r, echo = TRUE, eval=FALSE}
dt_iris[, head(.SD, 2), by = Species]

```

# Questions?

# Exercises

## Exercises

1 - Tidy the data below:

```{r, echo = TRUE,}
data <- tibble(
  group = c("treat", "control"),
  survival = c(17, 11),
  deceased = c(3, 9)
)
```

## Exercises

2 - Join the dataset flights to the dataset airlines. What should the key(s) be? What do the different types of joins look like?

```{r, echo = TRUE,}
library(nycflights13)
data("flights")
data("airlines")
```

## Exercises

3 - Using flights and data.table, group based on cases that have dep_delay \< 0 and those that have arr_delay \> 0 and count the number in each group. How many groups/rows are there? How many in each group?

# Questions?
